{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9pvsfQOHEZx"
   },
   "source": [
    "<h1><center><b>Sequence Labeling</b></center></h1>\n",
    "\n",
    "---\n",
    "\n",
    "# Introduction\n",
    "\n",
    "Exploring sequence labeling problems in NLP: (i) _Part of Speech (POS) tagging;_ and (ii) _Named Entity Recognition_ (NER). Hidden Markov Model (HMM) are used first to resolve the problem of POS tagging. Conditional Random Fields (CRF) are then applied to find solutions for NER.\n",
    "\n",
    "Some important aspects of NER are uncovered that require external (human) intervention, for example, the choice of features.\n",
    "\n",
    "### Workflow\n",
    "\n",
    "- Part 1: sets up the environment through installation of the required dependencies and incorporates a kernel restart.\n",
    "- Part 2: downloads and explores the dataset.\n",
    "- Part 3: investigates the application of Viterbi to Part of Speech tagging.\n",
    "- Part 4: develops a CRF model for NER tasks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AzLLUuyG1kT7"
   },
   "source": [
    "# Part 1: Setting up the environment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yz1h_m_bnuze"
   },
   "outputs": [],
   "source": [
    "!pip3 install -U scikit-learn\n",
    "!pip3 install git+https://github.com/MeMartijn/updated-sklearn-crfsuite.git#egg=sklearn_crfsuite\n",
    "!pip3 install nltk\n",
    "\n",
    "from IPython.core.display import HTML\n",
    "HTML(\"<script>Jupyter.notebook.kernel.restart()</script>\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9gZlrtBsFfR"
   },
   "source": [
    "# Part 2: Getting Familiar with the Dataset\n",
    "\n",
    "**NLTK:** There are many datasets in **Natural Language Toolkit (NLTK)** library of Python (see https://www.nltk.org). The two most widely used existing NLTK corpora are:\n",
    "\n",
    "1. Penn TreeBank Corpus\n",
    "2. CoNLL Named Entity (NE) Chunk Corpus\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Aggce-aN8K2T"
   },
   "source": [
    "## Penn Treebank Corpus\n",
    "\n",
    "> The completion of this section prepares you to answer question 1 and 2 on **Project 1 Quiz questions**.\n",
    "\n",
    "The English Penn Treebank (PTB) corpus, and in particular the section of the corpus corresponding to the articles of _Wall Street Journal (WSJ)_, is one of the most well-known and used corpus for the evaluation of models for sequence labeling.\n",
    "\n",
    "The formalism that underlies the POS tags assigned in the Penn Treebank is the _constituency tree_, which captures _syntactic categories_ (i.e., parts of speech) and relationships among words in a sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z2exon7N8SgJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ...]\n",
      "[('Rudolph', 'NNP'), ('Agnew', 'NNP'), (',', ','), ...]\n",
      "[('A', 'DT'), ('form', 'NN'), ('of', 'IN'), ...]\n",
      "[('Yields', 'NNS'), ('on', 'IN'), ...]\n",
      "[('J.P.', 'NNP'), ('Bolduc', 'NNP'), (',', ','), ...]\n",
      "199\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to\n",
      "[nltk_data]     /Users/krishnakodali/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import ssl\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "nltk.download(\"treebank\")\n",
    "\n",
    "from nltk.corpus import treebank\n",
    "\n",
    "for fileid in treebank.fileids()[:5]:\n",
    "    print(treebank.tagged_words(fileid))\n",
    "\n",
    "print(len(treebank.fileids()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ymq477gPyDI"
   },
   "source": [
    "### An Alternative Annotation Scheme: Universal Dependencies\n",
    "\n",
    "An alternative format is the _dependency tree_ representation, which is intended to provide a logical form that captures semantic relationships.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DUUDPR3HLq95"
   },
   "source": [
    "### CoNLL Corpus - 2002\n",
    "\n",
    "The CONLL-2002 dataset covers two languages: Spanish and Dutch. The Spanish dataset is a collection of newswire articles made available by the Spanish EFE News Agency. The articles are from May 2000. The tagged dataset contains words and entity tags only. The Dutch data consist of four editions of the Belgian newspaper \"De Morgen\" of 2000 (June 2, July 1, August 1 and September 1).\n",
    "\n",
    "The files available in the CoNLL corpus include train and test data for the three parts of the CoNLL-2002 shared task:\n",
    "\n",
    "1. esp.testa: Spanish test data for the development stage\n",
    "2. esp.testb: Spanish test data\n",
    "3. esp.train: Spanish train data\n",
    "4. ned.testa: Dutch test data for the development stage\n",
    "5. ned.testb: Dutch test data\n",
    "6. ned.train: Dutch train data\n",
    "\n",
    "CoNLL corpus 2002 using _ConllCorpusReader_ which is available in NLTK library. A _ConllCorpusReader_ expects a data file with the following columnn types:\n",
    "\n",
    "COLUMN_TYPES = ('words', 'pos', 'tree', 'chunk', 'ne', 'srl', 'ignore')\n",
    "where\n",
    "\n",
    "1. 'words': column type for words\n",
    "2. 'pos': column type for Part of Speech\n",
    "3. 'tree': column type for parse tree\n",
    "4. 'chunk': column type for short phrases present in a given structure\n",
    "5. 'ne': column type for named entities\n",
    "6. 'srl': column type for Semantic Role Labeling\n",
    "7. 'ignore': column type which can be ignored\n",
    "\n",
    "All data files contain a single word per line with an associated named entity tag in the IOB2 format. The IOB2 format (short for inside, outside, beginning) is a common tagging format for tagging tokens in a chunking task in computational linguistics. The _I-_ prefix before a tag indicates that the tag is inside a chunk. An _O_ tag indicates that a token belongs to no chunk. The _B-_ prefix before a tag indicates that the tag is the beginning of every chunk that immediately follows another chunk without _O_ tags between them.\n",
    "\n",
    "For example:\n",
    "Alex (_B-PER_)\n",
    "is (_O_)\n",
    "going (_O_)\n",
    "to (_O_)\n",
    "Los (_B-LOC_)\n",
    "Angeles (_I-LOC_)\n",
    "in (_O_)\n",
    "California (_B-LOC_).\n",
    "\n",
    "Sentence breaks are encoded as empty lines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDLjHI_FoDS_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['esp.testa', 'esp.testb', 'esp.train', 'ned.testa', 'ned.testb', 'ned.train']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package conll2002 to\n",
      "[nltk_data]     /Users/krishnakodali/nltk_data...\n",
      "[nltk_data]   Package conll2002 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import sklearn_crfsuite\n",
    "\n",
    "nltk.download(\"conll2002\")\n",
    "print(nltk.corpus.conll2002.fileids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKE1hkjfLw-9"
   },
   "source": [
    "# Part 4. Part of Speech Tagging\n",
    "\n",
    "Part-of-speech (POS) tagging is commonly used technology in Natural Language Processing that categorizes words of a text (corpus) in terms of specific parts of speech, depending on the definition of the word and its context.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "09mHbCLnDyeo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DISPLAYING SENTENCES\n",
      "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], [('Rudolph', 'NNP'), ('Agnew', 'NNP'), (',', ','), ('55', 'CD'), ('years', 'NNS'), ('old', 'JJ'), ('and', 'CC'), ('former', 'JJ'), ('chairman', 'NN'), ('of', 'IN'), ('Consolidated', 'NNP'), ('Gold', 'NNP'), ('Fields', 'NNP'), ('PLC', 'NNP'), (',', ','), ('was', 'VBD'), ('named', 'VBN'), ('*-1', '-NONE-'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('of', 'IN'), ('this', 'DT'), ('British', 'JJ'), ('industrial', 'JJ'), ('conglomerate', 'NN'), ('.', '.')], [('A', 'DT'), ('form', 'NN'), ('of', 'IN'), ('asbestos', 'NN'), ('once', 'RB'), ('used', 'VBN'), ('*', '-NONE-'), ('*', '-NONE-'), ('to', 'TO'), ('make', 'VB'), ('Kent', 'NNP'), ('cigarette', 'NN'), ('filters', 'NNS'), ('has', 'VBZ'), ('caused', 'VBN'), ('a', 'DT'), ('high', 'JJ'), ('percentage', 'NN'), ('of', 'IN'), ('cancer', 'NN'), ('deaths', 'NNS'), ('among', 'IN'), ('a', 'DT'), ('group', 'NN'), ('of', 'IN'), ('workers', 'NNS'), ('exposed', 'VBN'), ('*', '-NONE-'), ('to', 'TO'), ('it', 'PRP'), ('more', 'RBR'), ('than', 'IN'), ('30', 'CD'), ('years', 'NNS'), ('ago', 'IN'), (',', ','), ('researchers', 'NNS'), ('reported', 'VBD'), ('0', '-NONE-'), ('*T*-1', '-NONE-'), ('.', '.')], [('The', 'DT'), ('asbestos', 'NN'), ('fiber', 'NN'), (',', ','), ('crocidolite', 'NN'), (',', ','), ('is', 'VBZ'), ('unusually', 'RB'), ('resilient', 'JJ'), ('once', 'IN'), ('it', 'PRP'), ('enters', 'VBZ'), ('the', 'DT'), ('lungs', 'NNS'), (',', ','), ('with', 'IN'), ('even', 'RB'), ('brief', 'JJ'), ('exposures', 'NNS'), ('to', 'TO'), ('it', 'PRP'), ('causing', 'VBG'), ('symptoms', 'NNS'), ('that', 'WDT'), ('*T*-1', '-NONE-'), ('show', 'VBP'), ('up', 'RP'), ('decades', 'NNS'), ('later', 'JJ'), (',', ','), ('researchers', 'NNS'), ('said', 'VBD'), ('0', '-NONE-'), ('*T*-2', '-NONE-'), ('.', '.')]]\n",
      "DISPLAYING WORDS\n",
      "('Pierre', 'NNP')\n",
      "('Vinken', 'NNP')\n",
      "(',', ',')\n",
      "('61', 'CD')\n",
      "('years', 'NNS')\n",
      "('Mr.', 'NNP')\n",
      "('Vinken', 'NNP')\n",
      "('is', 'VBZ')\n",
      "('chairman', 'NN')\n",
      "('of', 'IN')\n"
     ]
    }
   ],
   "source": [
    "nltk_data = list(nltk.corpus.treebank.tagged_sents())\n",
    "\n",
    "print(\"DISPLAYING SENTENCES\")\n",
    "print(nltk_data[:5])\n",
    "\n",
    "print(\"DISPLAYING WORDS\")\n",
    "for sent in nltk_data[:2]:\n",
    "    for tuple in sent[:5]:\n",
    "        print(tuple)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pXXYO4leU_P4"
   },
   "source": [
    "## Training and Test Samples\n",
    "\n",
    "Apply a 80:20 ratio to divide the training and test sets, and then compute the number of training and test samples for each set. Following this, the unique tags in the training data are counted.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9In3O4iwKdVN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80310\n",
      "20366\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Drink', 'NN'),\n",
       " ('Carrier', 'NN'),\n",
       " ('Competes', 'VBZ'),\n",
       " ('With', 'IN'),\n",
       " ('Cartons', 'NNS')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set, test_set = train_test_split(\n",
    "    nltk_data, train_size=0.80, test_size=0.20, random_state=101\n",
    ")\n",
    "\n",
    "train_tagged_words = [tup for sent in train_set for tup in sent]\n",
    "test_tagged_words = [tup for sent in test_set for tup in sent]\n",
    "print(len(train_tagged_words))\n",
    "print(len(test_tagged_words))\n",
    "\n",
    "train_tagged_words[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBTkRQIBSp25"
   },
   "source": [
    "**Run the code below to count unique tags present in training data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DREaKSNdKnhj"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "{'CD', 'WDT', 'WP$', 'PRP$', 'TO', 'NNPS', ',', 'WP', 'RBR', '-LRB-', 'JJS', '#', ':', 'MD', 'VB', 'EX', 'VBD', 'RP', 'RBS', 'NNP', 'POS', '.', '``', '-NONE-', 'VBP', 'PRP', 'FW', 'UH', 'CC', 'IN', \"''\", 'DT', 'NN', 'PDT', 'VBG', '-RRB-', 'JJR', 'NNS', '$', 'WRB', 'JJ', 'VBZ', 'RB', 'VBN', 'LS'}\n"
     ]
    }
   ],
   "source": [
    "tags = {tag for _, tag in train_tagged_words}\n",
    "print(len(tags))\n",
    "print(tags)\n",
    "\n",
    "vocab = {word for word, _ in train_tagged_words}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q8FzkIyjwhSD"
   },
   "source": [
    "**45 tags in the training data**, including the -LRB- and -RRB- tags, which refer to \"(\" and \")\" are observed respectively. The resulting number of tags suggests that 3 out of 48 tags are not present in the training corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9eahxePaVnrb"
   },
   "source": [
    "## Hidden Markov Model (HMM)\n",
    "\n",
    "HMM is a probabilistic sequence model that leverages the principle of joint probability distribution. Two probabilities are calculated for decoding algorithm _'Viterbi Algorithm'_:\n",
    "\n",
    "1. Emission Probability\n",
    "2. Transition Probability\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SgTio8-ZS4HI"
   },
   "source": [
    "### Emission Probability\n",
    "\n",
    "Emission probability, also referred to as _operational likelihood_, expresses the probability that a word is generated from a tag. First find the _tag list_ and then _count tags_ to compute the emission probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvqSMg2BKrtN"
   },
   "outputs": [],
   "source": [
    "def word_given_tag(word, tag, train_bag=train_tagged_words):\n",
    "    \"\"\"\n",
    "    This function accepts word, tag and tagged words in training data to return count(w|tag) and count(tag)\n",
    "    \"\"\"\n",
    "    word_tag_pairs = [(_word, _tag) for (_word, _tag) in train_bag if tag == _tag]\n",
    "    return len([_word for (_word, _tag) in word_tag_pairs if _word == word]), len(\n",
    "        word_tag_pairs\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SJEWpWQnpnrY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed!\n",
      "The output must look like:\n",
      " The output for count_w_given_tag is:  1 \n",
      " The output for count_tag is:  10510\n",
      "OUTPUT:\n",
      "The output for count_w_given_tag is:  1\n",
      "The output for count_tag is:  10510\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert word_given_tag(\"Drink\", \"NN\")\n",
    "    assert word_given_tag(\"With\", \"IN\")\n",
    "    count_w_given_tag, count_tag = word_given_tag(\"Drink\", \"NN\")\n",
    "    print(\"Test Passed!\")\n",
    "    print(\n",
    "        \"The output must look like:\\n The output for count_w_given_tag is:  1 \\n The output for count_tag is:  10510\"\n",
    "    )\n",
    "    print(\"OUTPUT:\")\n",
    "    print(\"The output for count_w_given_tag is: \", count_w_given_tag)\n",
    "    print(\"The output for count_tag is: \", count_tag)\n",
    "except AssertionError as e:\n",
    "    print(\"Test Failed\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9LhDReofUxd6"
   },
   "source": [
    "### Transition Probability\n",
    "\n",
    "HMM is based on the principle of random walk. An HMM-based solution obtains the probability of moving from one hidden state (tag-1 (t1)) to another hidden state (tag-2 (t2)) with a transition probability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Sg5hegHKuay"
   },
   "outputs": [],
   "source": [
    "def t2_given_t1(t2, t1, train_bag=train_tagged_words):\n",
    "    \"\"\"\n",
    "    This function accepts two adjacent tags appearing in the text and tagged words in training data to return the count(t2|t1) and count(t1)\n",
    "    \"\"\"\n",
    "    t2_t1_count, t1_count = 0, 0\n",
    "    for index in range(len(train_bag)):\n",
    "        if train_bag[index][1] == t1:\n",
    "            t1_count += 1\n",
    "            if index < len(train_bag) - 1 and train_bag[index + 1][1] == t2:\n",
    "                t2_t1_count += 1\n",
    "\n",
    "    return t2_t1_count, t1_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fRNzFJ5Jsr9q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed!\n",
      "The output must look like:\n",
      " The output for count_t2_t1 is: 468 \n",
      " The output for count_t1 is:  10510\n",
      "OUTPUT:\n",
      "The output for count_t2_t1 is:  468\n",
      "The output for count_t1 is:  10510\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert t2_given_t1(\"VBZ\", \"NN\")\n",
    "    assert t2_given_t1(\"NN\", \"NN\")\n",
    "    assert t2_given_t1(\"IN\", \"VBZ\")\n",
    "    print(\"Test Passed!\")\n",
    "    count_t2_t1, count_t1 = t2_given_t1(\"VBZ\", \"NN\")\n",
    "    print(\n",
    "        \"The output must look like:\\n The output for count_t2_t1 is: 468 \\n The output for count_t1 is:  10510\"\n",
    "    )\n",
    "    print(\"OUTPUT:\")\n",
    "    print(\"The output for count_t2_t1 is: \", count_t2_t1)\n",
    "    print(\"The output for count_t1 is: \", count_t1)\n",
    "except AssertionError as e:\n",
    "    print(\"Test Failed\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DRclw7XGX9Ww"
   },
   "source": [
    "### Transition Probability Matrix\n",
    "\n",
    "A transition probability matrix (tags_matrix) is used to describe the probability of a tag, given the previous tag (to its left). Such transitions are accessed by sequence labeling processes, such as POS tagging and NER, to predict a tag for a word, given that of the previous word.\n",
    "\n",
    "> _state probability = transition probability X emission probability_\n",
    "\n",
    "> It might take a couple of minutes to calculate the following matrix.\\_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "175EQaeYKxiN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.18421993 0.00214209 0.00035702 ... 0.00249911 0.00357015 0.        ]\n",
      " [0.00561798 0.         0.         ... 0.00561798 0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.03222996 0.00130662 0.         ... 0.06968641 0.09581882 0.        ]\n",
      " [0.01056338 0.         0.         ... 0.02288732 0.0258216  0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "tags_matrix = np.zeros((len(tags), len(tags)), dtype=\"float32\")\n",
    "for i, t1 in enumerate(list(tags)):\n",
    "    for j, t2 in enumerate(list(tags)):\n",
    "        tags_matrix[i, j] = t2_given_t1(t2, t1)[0] / t2_given_t1(t2, t1)[1]\n",
    "\n",
    "print(tags_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQb92taHK0Dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            CD       WDT       WP$      PRP$        TO      NNPS         ,  \\\n",
      "CD    0.184220  0.002142  0.000357  0.000357  0.025705  0.000000  0.059265   \n",
      "WDT   0.005618  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "WP$   0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "PRP$  0.022727  0.000000  0.000000  0.000000  0.000000  0.001623  0.001623   \n",
      "TO    0.074826  0.000000  0.000000  0.015661  0.000000  0.000000  0.000000   \n",
      "\n",
      "            WP       RBR     -LRB-  \n",
      "CD    0.000357  0.000714  0.001428  \n",
      "WDT   0.000000  0.000000  0.000000  \n",
      "WP$   0.000000  0.000000  0.000000  \n",
      "PRP$  0.000000  0.000000  0.001623  \n",
      "TO    0.000000  0.000580  0.000000  \n"
     ]
    }
   ],
   "source": [
    "tags_df = pd.DataFrame(tags_matrix, columns=list(tags), index=list(tags))\n",
    "print(tags_df.iloc[:, :10].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B09vb-OfZNPG"
   },
   "source": [
    "## Viterbi Algorithm\n",
    "\n",
    "The Viterbi Algorithm is a dynamic programming decoder for HMMs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rZTov4fUPWCP"
   },
   "outputs": [],
   "source": [
    "def compute_state_probability(key, word, T, state):\n",
    "    \"\"\"\n",
    "    This function accepts key, word, list of tags T, the previous state (tag) and returns the list of probabilities of each tag in T\n",
    "    being the next state\n",
    "    \"\"\"\n",
    "    state_probabilities = []\n",
    "    for tag in T:\n",
    "        if key == 0:\n",
    "            transition_p = tags_df.loc[\".\", tag]\n",
    "        else:\n",
    "            transition_p = tags_df.loc[state[-1], tag]\n",
    "\n",
    "        wgt = word_given_tag(word, tag)\n",
    "        emission_p = wgt[0] / wgt[1]\n",
    "        state_p = transition_p * emission_p\n",
    "        state_probabilities.append(float(state_p))\n",
    "\n",
    "    return state_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K73mqCPnsCSV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed!\n",
      "The output must look like:\n",
      " The output for p is: [0, 0, 0, ..., 0.0003800179891361825,..., 0, 0, 0]\n",
      "OUTPUT:\n",
      "The output for p is:  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0003800179692916572, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    state_probabilities = []\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_tagged_words]))\n",
    "    assert compute_state_probability(0, \"At\", T, state)\n",
    "    state_probabilities = compute_state_probability(0, \"At\", T, state)\n",
    "    print(\"Test Passed!\")\n",
    "    print(\n",
    "        \"The output must look like:\\n The output for p is: [0, 0, 0, ..., 0.0003800179891361825,..., 0, 0, 0]\"\n",
    "    )\n",
    "    print(\"OUTPUT:\")\n",
    "    print(\"The output for p is: \", state_probabilities)\n",
    "except AssertionError as e:\n",
    "    print(\"Test Failed\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-XHb6zUUIvu"
   },
   "source": [
    "**Define the function for Viterbi algorithm.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "tr7_hdG4K2oi"
   },
   "outputs": [],
   "source": [
    "def Viterbi(words, train_bag=train_tagged_words):\n",
    "    state = []\n",
    "    T = list(set([pair[1] for pair in train_bag]))\n",
    "\n",
    "    for key, word in enumerate(words):\n",
    "        p = compute_state_probability(key, word, T, state)\n",
    "        pmax = max(p)\n",
    "\n",
    "        state_max = T[p.index(pmax)]\n",
    "        state.append(state_max)\n",
    "    return list(zip(words, state))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BpDfosTwaECM"
   },
   "source": [
    "**Execute this code to test the Viterbi algorithm on a few sample sentences of test dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQkfoAHnK5Mp"
   },
   "outputs": [],
   "source": [
    "random.seed(1234)  # define a random seed to get same sentences when run multiple times\n",
    "random_numbers = [random.randint(1, len(test_set)) for x in range(10)]\n",
    "\n",
    "test_subset = [test_set[i] for i in random_numbers]\n",
    "\n",
    "test_subset_base = [tup for sent in test_subset for tup in sent]  # tagged words\n",
    "\n",
    "test_subset_words = [tup[0] for sent in test_subset for tup in sent]  # untagged words\n",
    "\n",
    "test_subset_tags = [\n",
    "    tup[1] for sent in test_subset for tup in sent\n",
    "]  # tags in test subset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NC3DAQBhaURA"
   },
   "source": [
    "## Viterbi Evaluation for POS Tagging\n",
    "\n",
    "The Viterbi algorithm first sets up a lattice with one column for each word, and rows for tags where each cell represents each tag. Each cell $\\mathrm{t_i}$ of the lattice represents the probability of that the HMM is in a given state after seeing the the previous observations (words: $\\mathrm{w_1, w_2, ..., w_{i-1}}$) and passing through the most probable cell sequence $\\mathrm{t_1, t_2, ..., t_{i-1}}$. The value of each cell is computed by recursively taking the most probable path (the maximum over all possible previous state sequences) that could lead us to this cell.\n",
    "\n",
    "One way to evaluate the accuracy of sequence labeling problems is to compare the output tags (tagged_seq) for an input sequence (test_subset_words) to a human-labeled sequence that is already know to be correct (test_subset_base). Here, only 10 sentences are verified to check the accuracy as verification of the entire test set takes a very long time. Technically this notion of \"accuracy\" is referred to as \"precision\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "PpcG2OpmK7v1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken in seconds:  14.819891929626465\n",
      "Viterbi Algorithm Accuracy:  90.43062200956938\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "tagged_seq = Viterbi(test_subset_words)\n",
    "end = time.time()\n",
    "difference = end - start\n",
    "\n",
    "print(\"Time taken in seconds: \", difference)\n",
    "\n",
    "check = [i for i, j in zip(tagged_seq, test_subset_base) if i == j]\n",
    "\n",
    "accuracy = len(check) / len(tagged_seq)\n",
    "print(\"Viterbi Algorithm Accuracy: \", accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOjW8_hdcCVF"
   },
   "source": [
    "The Viterbi algorithm accuracy was computed above on 10 randomly chosen sentences. Exploit the resulting tagged sequence and test\\*subset_base to obtain more refined classification results, in terms of precision, recall, F1, and support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yIfNjq6daPeu"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          IN       1.00      1.00      1.00        16\n",
      "          JJ       0.86      0.86      0.86         7\n",
      "          NN       0.96      0.90      0.93        29\n",
      "          VB       0.80      0.67      0.73         6\n",
      "          RB       1.00      0.91      0.95        11\n",
      "          DT       1.00      1.00      1.00        17\n",
      "          CC       1.00      1.00      1.00         4\n",
      "\n",
      "   micro avg       0.97      0.92      0.94        90\n",
      "   macro avg       0.95      0.90      0.92        90\n",
      "weighted avg       0.96      0.92      0.94        90\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "actual_labels = [index for _, index in test_subset_base]\n",
    "predict_labels = [index for _, index in tagged_seq]\n",
    "labels = [\"IN\", \"JJ\", \"NN\", \"VB\", \"RB\", \"DT\", \"CC\"]\n",
    "\n",
    "results = classification_report(\n",
    "    actual_labels, predict_labels, labels=labels, zero_division=0\n",
    ")\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yN-gptggogUG"
   },
   "source": [
    "# Named Entity Recognition\n",
    "\n",
    "Named-entity recognition (NER), also known as (named) entity identification, entity chunking, and entity extraction, is a subtask of information extraction that seeks to locate and classify named entities mentioned in unstructured text into predefined categories such as person names, organizations, locations.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IzqIx2jiRX3Q"
   },
   "source": [
    "## CoNLL2002 dataset\n",
    "\n",
    "CoNLL2002 corpus will be used for the NER task that was downloaded earlier. There are as many as 6 fileids available in the dataset. In each file, every line represents a tagged word seperated by an empty space as _'word pos_tag NER_tag'_. Thus, three columns in every line consists of\n",
    "\n",
    "1. The first column: Word\n",
    "2. The second column: POS tag\n",
    "3. The third column: Named entity\n",
    "\n",
    "The data are represented with BIO tagging.\n",
    "\n",
    "For this, let's focus on the simpler BIO tagging scheme: any token that begins a span of interest is labeled B, tokens that occur inside a span are labeled I, and any tokens outside of any span of interest are labeled O. Also, labels are augmented with named-entity tags:\n",
    "\n",
    "1. 'B-LOC' : beginning location\n",
    "2. 'B-MISC': beginning miscellaneous\n",
    "3. 'B-ORG' : beginning organization\n",
    "4. 'B-PER' : beginning person\n",
    "5. 'I-LOC' : inside location\n",
    "6. 'I-MISC': inside miscellaneous\n",
    "7. 'I-ORG' : inside organization\n",
    "8. 'I-PER' : inside person\n",
    "9. 'O'. : Outside of span of interest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "efUpfDjYJRJG"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sao NC B-LOC\n",
      "Paulo VMI I-LOC\n",
      "( Fpa O\n",
      "Brasil NC B-LOC\n",
      ") Fpt O\n",
      ", Fc O\n",
      "23 Z O\n",
      "may NC O\n",
      "( Fpa O\n",
      "EFECOM N\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.conll2002.raw(\"esp.testa\")[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GrjJGFdq8jp-"
   },
   "source": [
    "## Training and Test Samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TijF_9RMSzRC"
   },
   "source": [
    "Train and test a NER model using Spanish data from the CoNLL2002 dataset. The model is trained on _'esp.train'_ and tested on _'esp.testb'_ Dataset is extracted into two variables, _train_sents_ and _test_sents_, respectively. The _iob_sents_ function extracts the raw text of file in the form of a list of _tuples <word, pos_tag, ner_tag>_ for each sentence.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "id": "ftr5HiOCoLCt"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Melbourne', 'NP', 'B-LOC'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('Australia', 'NP', 'B-LOC'),\n",
       " (')', 'Fpt', 'O'),\n",
       " (',', 'Fc', 'O'),\n",
       " ('25', 'Z', 'O'),\n",
       " ('may', 'NC', 'O'),\n",
       " ('(', 'Fpa', 'O'),\n",
       " ('EFE', 'NC', 'B-ORG'),\n",
       " (')', 'Fpt', 'O'),\n",
       " ('.', 'Fp', 'O')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_sents = list(nltk.corpus.conll2002.iob_sents(\"esp.train\"))\n",
    "test_sents = list(nltk.corpus.conll2002.iob_sents(\"esp.testb\"))\n",
    "\n",
    "train_sents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "x272gvXeQTDk"
   },
   "outputs": [],
   "source": [
    "def compute_tag_distribution(sents):\n",
    "    \"\"\"\n",
    "    This function accepts a tuple <word, pos, ner> to return the NER_tag frequency distribution\n",
    "    \"\"\"\n",
    "    ner_tag_frequency = dict()\n",
    "    for sent in sents:\n",
    "        for word, _, ner in sent:\n",
    "            if ner not in ner_tag_frequency:\n",
    "                ner_tag_frequency[ner] = 1\n",
    "            else:\n",
    "                ner_tag_frequency[ner] += 1\n",
    "\n",
    "    return ner_tag_frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "-Fx2PhMkREmn"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed!\n",
      "The output for training corpora must look like: {'B-LOC': 4913, 'O': 231920, 'B-ORG': 7390, 'B-PER': 4321, ...} \n",
      "OUTPUT for train_sents ner_tag_frequency is: {'B-LOC': 4913, 'O': 231920, 'B-ORG': 7390, 'B-PER': 4321, 'I-PER': 3903, 'B-MISC': 2173, 'I-ORG': 4992, 'I-LOC': 1891, 'I-MISC': 3212}\n",
      "The output for test corpora must look like: {'B-LOC': 1084, 'I-LOC': 325, 'O': 45355, 'B-ORG': 1400, ...} \n",
      "OUTPUT for test_sents ner_tag_frequency is: {'B-LOC': 1084, 'I-LOC': 325, 'O': 45355, 'B-ORG': 1400, 'B-MISC': 339, 'B-PER': 735, 'I-PER': 634, 'I-ORG': 1104, 'I-MISC': 557}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert compute_tag_distribution(train_sents)\n",
    "    assert compute_tag_distribution(test_sents)\n",
    "    train_ner_tag_frequency = compute_tag_distribution(train_sents)\n",
    "    test_ner_tag_frequency = compute_tag_distribution(test_sents)\n",
    "    print(\"Test Passed!\")\n",
    "    print(\n",
    "        \"The output for training corpora must look like: {'B-LOC': 4913, 'O': 231920, 'B-ORG': 7390, 'B-PER': 4321, ...} \"\n",
    "    )\n",
    "    print(\"OUTPUT for train_sents ner_tag_frequency is:\", train_ner_tag_frequency)\n",
    "    print(\n",
    "        \"The output for test corpora must look like: {'B-LOC': 1084, 'I-LOC': 325, 'O': 45355, 'B-ORG': 1400, ...} \"\n",
    "    )\n",
    "    print(\"OUTPUT for test_sents ner_tag_frequency is:\", test_ner_tag_frequency)\n",
    "except AssertionError as e:\n",
    "    print(\"Test Failed\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0JadtErrT0CZ"
   },
   "source": [
    "The NER tag distribution differs due to the size difference between the training and test corpora. However, the distributions follows a similar trend, with the highest number of tags being \"O\", etc. in both distributions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tVxtE22gonFs"
   },
   "source": [
    "## Feature Extraction\n",
    "\n",
    "As a starting point for the named-entity recognition task, features are extracted for every word. A feature is an individual measurable property or characteristic of a word, for example, its part of speech (e.g., the POS for \"eat\" is a Verb). Choosing informative, discriminating and independent features is crucial for development of effective algorithms in pattern recognition, classification and regression. Producing accurate output for sequence labeling relies crucially on careful selection of features.\n",
    "\n",
    "In addition to POS tags, other types of features may be extracted, e.g., word parts, simplified POS tags, lower/title/upper case flags, and features of nearby words. To employ all such features in the task of Named Entity recognition, covert them into sklearn-crfsuite format. Each sentence is converted into a list of dicts, i.e., a dictionary that maps feature names to feature indices which is a very simple baseline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f_KUtpOLl20k"
   },
   "source": [
    "The following feature extraction steps are added for a given word and its neighbors (steps 1, 2, 3, and 4 refer to boolean values and 5 refers to a multi-category POS):\n",
    "\n",
    "1. Word is lower-case (non-capitalized letters, e.g., \"a\")\n",
    "2. Case of a word is `upper' (capitalized letters, e.g., \"A\")\n",
    "3. Word is title (e.g., \"Mr.\")\n",
    "4. Word is a digit (e.g., \"10\")\n",
    "5. POS tag of word (e.g., \"JJ\")\n",
    "6. Repeat steps from 2 to 5 for its neighbors\n",
    "\n",
    "Tag frequency may influence the feature vector. Thus, features need to be weighted according to the number of times their corresponding tag appears. This introduces 'bias', an independent feature, which balances out the influence of varying tag frequency in the training corpus. Using 'bias' is a prevailing approach to address _feature bias_ in adjusting the training loss for manually designed biased features. However currently, simplify assumption of uniform NER tag frequency distribution during model, e.g., ORG is assumed to occur as frequently as PERS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "7eNhw5pTU2iv"
   },
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    \"\"\"\n",
    "    This function accepts a sent (list of tuple in sentence) to return the additional features.\n",
    "    \"\"\"\n",
    "\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        \"bias\": 1.0,\n",
    "        \"word.lower()\": word.lower(),\n",
    "        \"word[-3:]\": word[-3:],\n",
    "        \"word[-2:]\": word[-2:],\n",
    "        \"word.isupper()\": word.isupper(),\n",
    "        \"word.istitle()\": word.istitle(),\n",
    "        \"word.isdigit()\": word.isdigit(),\n",
    "        \"postag\": postag,\n",
    "        \"postag[:2]\": postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i - 1][0]\n",
    "        postag1 = sent[i - 1][1]\n",
    "\n",
    "        features.update(\n",
    "            {\n",
    "                \"-1:word.lower()\": word1.lower(),\n",
    "                \"-1:word.istitle()\": word1.istitle(),\n",
    "                \"-1:word.isupper()\": word1.isupper(),\n",
    "                \"-1:postag\": postag1,\n",
    "                \"-1:postag[:2]\": postag1[:2],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        features[\"BOS\"] = True\n",
    "\n",
    "    if i < len(sent) - 1:\n",
    "        word1 = sent[i + 1][0]\n",
    "        postag1 = sent[i + 1][1]\n",
    "\n",
    "        features.update(\n",
    "            {\n",
    "                \"+1:word.lower()\": word1.lower(),\n",
    "                \"+1:word.istitle()\": word1.istitle(),\n",
    "                \"+1:word.isupper()\": word1.isupper(),\n",
    "                \"+1:postag\": postag1,\n",
    "                \"+1:postag[:2]\": postag1[:2],\n",
    "            }\n",
    "        )\n",
    "    else:\n",
    "        features[\"EOS\"] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "ees_fR0RjG2F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Passed!\n",
      "The output must look like: {'bias': 1.0, 'word.lower()': 'del', 'word[-3:]': 'del', ..., }\n",
      "OUTPUT:\n",
      "{'bias': 1.0, 'word.lower()': 'del', 'word[-3:]': 'del', 'word[-2:]': 'el', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'SP', 'postag[:2]': 'SP', '-1:word.lower()': 'petición', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NC', '-1:postag[:2]': 'NC', '+1:word.lower()': 'abogado', '+1:word.istitle()': True, '+1:word.isupper()': False, '+1:postag': 'NC', '+1:postag[:2]': 'NC'}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    assert word2features(train_sents[3], 2)\n",
    "    features = word2features(train_sents[3], 2)\n",
    "    print(\"Test Passed!\")\n",
    "    print(\n",
    "        \"The output must look like: {'bias': 1.0, 'word.lower()': 'del', 'word[-3:]': 'del', ..., }\"\n",
    "    )\n",
    "    print(\"OUTPUT:\")\n",
    "    print(features)\n",
    "except AssertionError as e:\n",
    "    print(\"Test Failed\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "bzoXo6ozojvb"
   },
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8mIGgJSmXHC"
   },
   "source": [
    "### Extracting features\n",
    "\n",
    "The input to feature extraction is a sentence. The characteristics for each word in a sentence are obtained as a set of _features_ in the form of a dictionary, as illustrated in Part 3. Will be using sent2feature and sent2labels for feature extraction at the sentence level, recursively extracting features at the word level using the word2feature function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4qQomxoH1ztZ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bias': 1.0,\n",
       " 'word.lower()': ')',\n",
       " 'word[-3:]': ')',\n",
       " 'word[-2:]': ')',\n",
       " 'word.isupper()': False,\n",
       " 'word.istitle()': False,\n",
       " 'word.isdigit()': False,\n",
       " 'postag': 'Fpt',\n",
       " 'postag[:2]': 'Fp',\n",
       " '-1:word.lower()': 'australia',\n",
       " '-1:word.istitle()': True,\n",
       " '-1:word.isupper()': False,\n",
       " '-1:postag': 'NP',\n",
       " '-1:postag[:2]': 'NP',\n",
       " '+1:word.lower()': ',',\n",
       " '+1:word.istitle()': False,\n",
       " '+1:word.isupper()': False,\n",
       " '+1:postag': 'Fc',\n",
       " '+1:postag[:2]': 'Fc'}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = [sent2features(s) for s in train_sents]\n",
    "y_train = [sent2labels(s) for s in train_sents]\n",
    "\n",
    "X_test = [sent2features(s) for s in test_sents]\n",
    "y_test = [sent2labels(s) for s in test_sents]\n",
    "\n",
    "X_train[0][3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uk2XkFQymeqW"
   },
   "source": [
    "## Conditional Random Field (CRF) model\n",
    "\n",
    "A Conditional Random Field (CRF) is a standard model for predicting the most likely sequence of labels that correspond to a sequence of inputs. CRF is a labeler in which the tag of the present word (denoted as yᵢ) depends only on the tag of just the previous word(denoted by yᵢ₋₁).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "Tn0ztc5FpCDP"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=1.0, c2=0.001,\n",
       "    max_iterations=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>CRF</div></div><div><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>CRF(algorithm=&#x27;lbfgs&#x27;, all_possible_transitions=True, c1=1.0, c2=0.001,\n",
       "    max_iterations=20)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_transitions=True, c1=1.0, c2=0.001,\n",
       "    max_iterations=20)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm=\"lbfgs\",\n",
    "    c1=1.0,\n",
    "    c2=1e-3,\n",
    "    max_iterations=20,\n",
    "    all_possible_transitions=True,\n",
    ")\n",
    "crf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qyNOj9PspG_0"
   },
   "source": [
    "## CRF Evaluation for Named Entity Recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "-oKoOlPxpHV5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       B-LOC       0.67      0.61      0.64      1084\n",
      "      B-MISC       0.35      0.10      0.15       339\n",
      "       B-ORG       0.66      0.76      0.71      1400\n",
      "       B-PER       0.74      0.77      0.75       735\n",
      "       I-LOC       0.49      0.24      0.32       325\n",
      "      I-MISC       0.55      0.20      0.30       557\n",
      "       I-ORG       0.63      0.79      0.70      1104\n",
      "       I-PER       0.81      0.89      0.85       634\n",
      "           O       0.99      1.00      0.99     45355\n",
      "\n",
      "    accuracy                           0.95     51533\n",
      "   macro avg       0.66      0.59      0.60     51533\n",
      "weighted avg       0.95      0.95      0.95     51533\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn_crfsuite.metrics import flat_classification_report\n",
    "import numpy as np\n",
    "\n",
    "y_pred = crf.predict(X_test)\n",
    "\n",
    "result = flat_classification_report(y_test, y_pred)\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "lucqqa3dIbr_"
   ],
   "provenance": [
    {
     "file_id": "1ehhHZAQK7yKk01e_bJiN7aqrQDUuqAe5",
     "timestamp": 1696259984762
    },
    {
     "file_id": "1fqlzQ81HahjmdWpsJohuLSA6u3pTde5E",
     "timestamp": 1664550598362
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
